'''
Train a CNN that predicts the stress contour in a cantilever beam with variable dimensions and a point load at the free end with variable magnitude and direction.


The input images are __________ images containing different information in each channel:
- __________ a white line oriented at the specific angle. Angle values follow the standard coordinate system and increase counterclockwise. An angle of 0 degrees points directly right, and an angle of 90 degrees points directly up. The output images are stress contours in the cantilever.
- __________

The output images are stress contours in the cantilever generated by FEA.
- Software: ANSYS (Mechanical APDL)
- Element type: PLANE182 (2D 4-node structural solid)
    - Thickness: 1
- Material: structural steel
    - Elastic modulus: 200 GPa
    - Poisson's ratio: 0.3
- Meshing: 20 divisions, global
'''


import colorsys
from dataclasses import dataclass
import glob
import os

import matplotlib.pyplot as plt
import numpy as np
from PIL import Image, ImageOps
import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader


# A dataclass that stores settings for each parameter.
@dataclass
class Parameter:
    # The minimum and maximum values between which samples are generated.
    low: float
    high: float
    # range: tuple
    # Number of decimal places to which sample values are rounded.
    precision: int
    # Name of the parameter.
    name: str
    # Units for the parameter.
    units: str = ''

# Define the settings for each parameter.
load = Parameter(low=10000, high=100000, precision=0, name='Load', units='N')
angle = Parameter(low=0, high=360, precision=2, name='Angle', units='Degrees')
length = Parameter(low=2, high=4, precision=3, name='Length', units='m')
height = Parameter(low=1, high=2, precision=3, name='Height', units='m')
# The two angle values near which there should be more samples than elsewhere.
ANGLE_PEAKS = (0, 180)

# Size of input images. Must have the same aspect ratio as the largest possible cantilever geometry.
INPUT_SIZE = (100, 50, 2)
assert (INPUT_SIZE[1] / INPUT_SIZE[0]) == (height.high / length.high), 'Input image size must match aspect ratio of cantilever.'
# Size of output images produced by the network. Output images produced by FEA will be resized to this size.
OUTPUT_SIZE = INPUT_SIZE[:2]

# Folders.
FOLDER_ROOT = 'Cantilever'
FOLDER_TRAIN_INPUTS = os.path.join(FOLDER_ROOT, 'Train Inputs')
FOLDER_TRAIN_OUTPUTS = os.path.join(FOLDER_ROOT, 'Train Outputs')
FOLDER_TEST_INPUTS = os.path.join(FOLDER_ROOT, 'Test Inputs')
FOLDER_TEST_OUTPUTS = os.path.join(FOLDER_ROOT, 'Test Outputs')

# Training hyperparameters.
BATCH_SIZE = 1
LEARNING_RATE = 0.1
EPOCHS = 30


# Create images for the sample values provided inside the specified folder.
def generate_input_images(samples, folder_inputs):
    # Remove existing input images in the folder.
    filenames = glob.glob(os.path.join(folder_inputs, '*.png'))
    for filename in filenames:
        os.remove(filename)
    print(f'Deleted {len(filenames)} existing images in {folder_inputs}.')

    filenames = []
    for load_sample, angle_sample, length_sample, height_sample in zip(*samples):
        image = np.zeros((INPUT_SIZE[1], INPUT_SIZE[0], INPUT_SIZE[2]))
        # Create a channel with a gray line of pixels representing the load magnitude and direction.
        r = np.arange(max(INPUT_SIZE))
        x = r * np.cos(angle_sample * np.pi/180) + INPUT_SIZE[0]/2
        y = r * np.sin(angle_sample * np.pi/180) + INPUT_SIZE[1]/2
        x = x.astype(int)
        y = y.astype(int)
        inside_image = (x >= 0) * (x < INPUT_SIZE[0]) * (y >= 0) * (y < INPUT_SIZE[1])
        image[y[inside_image], x[inside_image], 0] = 255 * (load_sample / load.high)
        image[:, :, 0] = np.flipud(image[:, :, 0])
        # Create a channel with a white rectangle representing the dimensions of the cantilever.
        image[
            :round(height_sample/height.high * image.shape[0]),
            :round(length_sample/length.high * image.shape[1]),
            1
            ] = 255
        # Write image files.
        filename = os.path.join(folder_inputs, f'input_{load_sample}_{angle_sample}_{length_sample}_{height_sample}.png')
        with Image.fromarray(image.astype(np.uint8), 'LA') as file:
            file.save(filename)
            filenames.append(filename)
    print(f'Wrote {len(samples[0])} input images in {folder_inputs}.')
    return filenames

# Convert a 3-channel RGB array into a 1-channel hue array with values in [0, 1].
def rgb_to_hue(array):
    array = array / 255
    hue_array = np.zeros((array.shape[0], array.shape[1]))
    for i in range(array.shape[0]):
        for j in range(array.shape[1]):
            hsv = colorsys.rgb_to_hsv(array[i, j, 0], array[i, j, 1], array[i, j, 2])
            hue_array[i, j] = hsv[0]
    return hue_array

# Convert a 3-channel HSV array into a 3-channel RGB array.
def hsv_to_rgb(array):
    for i in range(array.shape[0]):
        for j in range(array.shape[1]):
            rgb = colorsys.hsv_to_rgb(array[i, j, 0], array[i, j, 1], array[i, j, 2])
            for k in range(3):
                array[i, j, k] = rgb[k] * 255
    return array

# Dataset that retrieves input and output images for the CNN. Output images are not retrieved if the outputs folder is not specified.
class CantileverDataset(Dataset):
    def __init__(self, folder_inputs, folder_outputs=None):
        self.folder_inputs = folder_inputs
        self.folder_outputs = folder_outputs
        # Get all input image filenames in the inputs folder.
        self.filenames = glob.glob(os.path.join(self.folder_inputs, '*.png'))
        self.filename_suffixes = [filename.split('.')[-2].split('_')[1:] for filename in self.filenames]

    def __len__(self):
        return len(self.filenames)
    
    def __getitem__(self, index):
        filename_input = self.filenames[index]
        image_input = np.asarray(Image.open(filename_input), np.uint8)
        image_input = np.expand_dims(image_input, 0)
        if self.folder_outputs is not None:
            filename_output = os.path.join(
                self.folder_outputs,
                f'{"_".join(["stress"] + self.filename_suffixes[index])}.png',
                )
            image_output = np.asarray(Image.open(filename_output), np.uint8)[:, :, :3]
            image_output = rgb_to_hue(image_output).flatten()
        else:
            image_output = 0
        return image_input, image_output

# A CNN that predicts the stress contour in a cantilever beam with a point load at the free end.
class StressContourNetwork(nn.Module):
    def __init__(self):
        super().__init__()
        self.cnn = nn.Sequential(
            nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, stride=1),
            nn.BatchNorm2d(4),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(in_channels=4, out_channels=4, kernel_size=3, stride=1),
            nn.BatchNorm2d(4),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            )
        self.linear = nn.Sequential(
            nn.Linear(in_features=2116, out_features=OUTPUT_SIZE[0]*OUTPUT_SIZE[1]),
        )
    
    def forward(self, x):
        x = x.float()
        x = self.cnn(x)
        x = x.view(x.size(0), -1)
        x = self.linear(x)
        return x

# Train the model for one epoch only.
def train(dataloader, model, loss_function, optimizer):
    for batch, (data, label) in enumerate(dataloader):
        data = data.to(device)
        label = label.to(device)
        
        output = model(data)
        loss = loss_function(output, label.float())

        # Reset gradients of model parameters.
        optimizer.zero_grad()
        # Backpropagate the prediction loss.
        loss.backward()
        # Adjust model parameters.
        optimizer.step()

        if batch % (BATCH_SIZE * 10) == 0:
            loss, current = loss.item(), batch * len(data)
            print(f'Loss: {loss:>7f}  (batch {current} of {len(dataloader.dataset)})')

# Test the model for one epoch only.
def test(dataloader, model, loss_function):
    batch_count = len(dataloader)
    test_loss = 0

    with torch.no_grad():
        for data, label in dataloader:
            data = data.to(device)
            label = label.to(device)
            output = model(data)
            test_loss += loss_function(output, label.float())

    test_loss /= batch_count
    print(f'Average loss: {test_loss:>8f}')
    return test_loss


# Train and test the model.
if __name__ == '__main__':
    device = 'cpu'  #'cuda' if torch.cuda.is_available() else 'cpu'
    print(f'Using {device} device.')

    # Initialize the model.
    model = StressContourNetwork()
    
    # Set up the training data.
    train_dataset = CantileverDataset(FOLDER_TRAIN_INPUTS, FOLDER_TRAIN_OUTPUTS)
    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
    loss_function = nn.MSELoss()
    optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)

    # Train the model and record the accuracy and loss.
    test_loss_values = []
    for t in range(EPOCHS):
        print(f'Epoch {t+1}\n------------------------')
        train(train_dataloader, model, loss_function, optimizer)
        test_loss = test(train_dataloader, model, loss_function)
        test_loss_values.append(test_loss)
    
    # Plot the loss history.
    plt.figure()
    plt.plot(test_loss_values, '-o', color='#ffbf00')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.grid(axis='y')
    plt.show()

    # Set up the testing data.
    test_dataset = CantileverDataset(FOLDER_TEST_INPUTS, None)
    test_dataloader = DataLoader(test_dataset, shuffle=True)
    
    # Remove existing output images in the folder.
    filenames = glob.glob(os.path.join(FOLDER_TEST_OUTPUTS, '*.png'))
    for filename in filenames:
        os.remove(filename)
    print(f'Deleted {len(filenames)} existing images in {FOLDER_TEST_OUTPUTS}.')
    
    # Test the model on the input images found in the folder.
    for index, (test_input, _) in enumerate(test_dataloader):
        test_output = model(test_input).detach().numpy()[0, :]
        test_output = test_output.reshape(OUTPUT_SIZE, order='F')
        # Convert the output to an RGB array.
        test_output = np.dstack((test_output, np.ones(OUTPUT_SIZE, float), 2/3 * np.ones(OUTPUT_SIZE, float)))
        test_output = hsv_to_rgb(test_output)
        # Save the generated output image.
        test_output = test_output.transpose((1, 0, 2)).astype(np.uint8)
        with Image.fromarray(test_output) as image:
            image.save(os.path.join(
                FOLDER_TEST_OUTPUTS,
                f'{"_".join(["test"] + test_dataset.filename_suffixes[index])}.png',
                ))
    print(f'Wrote {len(test_dataloader)} output images in {FOLDER_TEST_OUTPUTS}.')